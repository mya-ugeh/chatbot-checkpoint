{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity      \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import spacy\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>How long uniform-cost search will take?</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>How much space does uniform-cost search take t...</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>How much space does iterative deepening search...</td>\n",
       "      <td>O(bd)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>How much space does depth-first search take to...</td>\n",
       "      <td>O(bm)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How much space does breadth-first search take ...</td>\n",
       "      <td>\"O(b^d) (keeps every node in memory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    Who did the first work generally recognized as...   \n",
       "1    What sources was drawn on the formation of the...   \n",
       "2               Who created the Hebbian learning rule?   \n",
       "3              When the first neural network is built?   \n",
       "4             What is the first neural network called?   \n",
       "..                                                 ...   \n",
       "498            How long uniform-cost search will take?   \n",
       "499  How much space does uniform-cost search take t...   \n",
       "500  How much space does iterative deepening search...   \n",
       "501  How much space does depth-first search take to...   \n",
       "502  How much space does breadth-first search take ...   \n",
       "\n",
       "                                                Answer  \n",
       "0          Warren McCulloch and Walter Pitts (1943).\\n  \n",
       "1    knowledge of the basic physiology and function...  \n",
       "2                                Donald Hebb (1949).\\n  \n",
       "3                                              1950.\\n  \n",
       "4                                         The SNARC.\\n  \n",
       "..                                                 ...  \n",
       "498  of nodes with path cost ≤ cost of optimal solu...  \n",
       "499  of nodes with path cost ≤ cost of optimal solu...  \n",
       "500                                            O(bd)\\n  \n",
       "501                                            O(bm)\\n  \n",
       "502                \"O(b^d) (keeps every node in memory  \n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AI.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Answer'] = data['Answer'].str.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>How long uniform-cost search will take?</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>How much space does uniform-cost search take t...</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>How much space does iterative deepening search...</td>\n",
       "      <td>O(bd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>How much space does depth-first search take to...</td>\n",
       "      <td>O(bm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How much space does breadth-first search take ...</td>\n",
       "      <td>\"O(b^d) (keeps every node in memory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    Who did the first work generally recognized as...   \n",
       "1    What sources was drawn on the formation of the...   \n",
       "2               Who created the Hebbian learning rule?   \n",
       "3              When the first neural network is built?   \n",
       "4             What is the first neural network called?   \n",
       "..                                                 ...   \n",
       "498            How long uniform-cost search will take?   \n",
       "499  How much space does uniform-cost search take t...   \n",
       "500  How much space does iterative deepening search...   \n",
       "501  How much space does depth-first search take to...   \n",
       "502  How much space does breadth-first search take ...   \n",
       "\n",
       "                                                Answer  \n",
       "0            Warren McCulloch and Walter Pitts (1943).  \n",
       "1    knowledge of the basic physiology and function...  \n",
       "2                                  Donald Hebb (1949).  \n",
       "3                                                1950.  \n",
       "4                                           The SNARC.  \n",
       "..                                                 ...  \n",
       "498  of nodes with path cost ≤ cost of optimal solu...  \n",
       "499  of nodes with path cost ≤ cost of optimal solu...  \n",
       "500                                              O(bd)  \n",
       "501                                              O(bm)  \n",
       "502                \"O(b^d) (keeps every node in memory  \n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('AI_FAQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AI_FAQ.csv')\n",
    "df.rename(columns={'Question' : 'Questions', 'Answer' : 'Answers'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>How long uniform-cost search will take?</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>How much space does uniform-cost search take t...</td>\n",
       "      <td>of nodes with path cost ≤ cost of optimal solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>How much space does iterative deepening search...</td>\n",
       "      <td>O(bd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>How much space does depth-first search take to...</td>\n",
       "      <td>O(bm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How much space does breadth-first search take ...</td>\n",
       "      <td>\"O(b^d) (keeps every node in memory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Questions  \\\n",
       "0    Who did the first work generally recognized as...   \n",
       "1    What sources was drawn on the formation of the...   \n",
       "2               Who created the Hebbian learning rule?   \n",
       "3              When the first neural network is built?   \n",
       "4             What is the first neural network called?   \n",
       "..                                                 ...   \n",
       "498            How long uniform-cost search will take?   \n",
       "499  How much space does uniform-cost search take t...   \n",
       "500  How much space does iterative deepening search...   \n",
       "501  How much space does depth-first search take to...   \n",
       "502  How much space does breadth-first search take ...   \n",
       "\n",
       "                                               Answers  \n",
       "0            Warren McCulloch and Walter Pitts (1943).  \n",
       "1    knowledge of the basic physiology and function...  \n",
       "2                                  Donald Hebb (1949).  \n",
       "3                                                1950.  \n",
       "4                                           The SNARC.  \n",
       "..                                                 ...  \n",
       "498  of nodes with path cost ≤ cost of optimal solu...  \n",
       "499  of nodes with path cost ≤ cost of optimal solu...  \n",
       "500                                              O(bd)  \n",
       "501                                              O(bm)  \n",
       "502                \"O(b^d) (keeps every node in memory  \n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Next step is tokenize our text dataset.<br>\n",
    "There are two types of tokenization:\n",
    "    <ol><li>Word Tokenization: This is  the process of breaking down a text or document into individual words or tokens.</li>\n",
    "    <li>Sent Tokenization: This is to break down the text data into individual sentences so that each sentence can be processed separately.</li><br></ol>\n",
    "Lemmatization: The goal of lemmatization is to reduce a word to its canonical form so that variations of the same word can be treated as the same token<br>\n",
    "For example, the word \"jumped\" may be lemmatized to \"jump\", and the word \"walking\" may be lemmatized to \"walk\".<br>\n",
    "By reducing words to their base forms, lemmatization can help to simplify text data and reduce the number of unique tokens that need to be analyzed or processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>tokenized Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).</td>\n",
       "      <td>who did the first work generally recognized a ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "      <td>what source wa drawn on the formation of the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).</td>\n",
       "      <td>who created the hebbian learning rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.</td>\n",
       "      <td>when the first neural network is built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.</td>\n",
       "      <td>what is the first neural network called</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Who did the first work generally recognized as...   \n",
       "1  What sources was drawn on the formation of the...   \n",
       "2             Who created the Hebbian learning rule?   \n",
       "3            When the first neural network is built?   \n",
       "4           What is the first neural network called?   \n",
       "\n",
       "                                             Answers  \\\n",
       "0          Warren McCulloch and Walter Pitts (1943).   \n",
       "1  knowledge of the basic physiology and function...   \n",
       "2                                Donald Hebb (1949).   \n",
       "3                                              1950.   \n",
       "4                                         The SNARC.   \n",
       "\n",
       "                                 tokenized Questions  \n",
       "0   who did the first work generally recognized a ai  \n",
       "1  what source wa drawn on the formation of the f...  \n",
       "2              who created the hebbian learning rule  \n",
       "3             when the first neural network is built  \n",
       "4            what is the first neural network called  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define a function for text preprocessing (including lemmatization)\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Identifies all sentences in the data\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize and lemmatize each word in each sentence\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = [lemmatizer.lemmatize(word.lower()) for word in nltk.word_tokenize(sentence) if word.isalnum()]\n",
    "        # Turns to basic root - each word in the tokenized word found in the tokenized sentence - if they are all alphanumeric \n",
    "        # The code above does the following:\n",
    "        # Identifies every word in the sentence \n",
    "        # Turns it to a lower case \n",
    "        # Lemmatizes it if the word is alphanumeric\n",
    "\n",
    "        preprocessed_sentence = ' '.join(tokens)\n",
    "        preprocessed_sentences.append(preprocessed_sentence)\n",
    "    \n",
    "    return ' '.join(preprocessed_sentences)\n",
    "\n",
    "\n",
    "df['tokenized Questions'] = df['Questions'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus by flattening the preprocessed questions\n",
    "corpus = df['tokenized Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize corpus\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "# TDIDF is a numerical statistic used to evaluate how important a word is to a document in a collection or corpus. \n",
    "# The TfidfVectorizer calculates the Tfidf values for each word in the corpus and uses them to create a matrix where each row represents a document and each column represents a word. \n",
    "# The cell values in the matrix correspond to the importance of each word in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot: Twale baba nla, wetin dey happen nah!\n",
      "\n",
      "Chatbot: Twale baba nla, wetin dey happen nah!\n",
      "\n",
      "Chatbot:  better\n",
      "\n",
      "Chatbot: Artificial Intelligence (AI) is the part of computer science concerned with designing intelligent computer systems.\n",
      "\n",
      "Chatbot: Thanks....see you soon!\n"
     ]
    }
   ],
   "source": [
    "def get_response(user_input):\n",
    "    global most_similar_index\n",
    "    \n",
    "    user_input_processed = preprocess_text(user_input) # ....................... Preprocess the user's input using the preprocess_text function\n",
    "\n",
    "    user_input_vector = tfidf_vectorizer.transform([user_input_processed])# .... Vectorize the preprocessed user input using the TF-IDF vectorizer\n",
    "\n",
    "    similarity_scores = cosine_similarity(user_input_vector, X) # .. Calculate the score of similarity between the user input vector and the corpus (df) vector\n",
    "\n",
    "    most_similar_index = similarity_scores.argmax() # ..... Find the index of the most similar question in the corpus (df) based on cosine similarity\n",
    "\n",
    "    return df['Answers'].iloc[most_similar_index] # ... Retrieve the corresponding answer from the df DataFrame and return it as the chatbot's response\n",
    "\n",
    "# create greeting list \n",
    "greetings = [\"Hey There, I am your assistant how may I help you\",\n",
    "            \"Hi Human.... How can I help\",\n",
    "            'Hello, there',\n",
    "            'HI! Great to have you here, how may I help?'\n",
    "            \"Good Day,How can I help\", \n",
    "            \"Hello There... How can I be useful to you today\",\n",
    "            \"Hi there, how may I be of help\"]\n",
    "\n",
    "exits = ['thanks bye', 'bye', 'quit', 'exit', 'bye bye', 'close']\n",
    "farewell = ['Thanks....see you soon', 'Babye, See you soon', 'Bye... See you later', 'Bye... come back soon']\n",
    "\n",
    "random_farewell = random.choice(farewell) # ---------------- Randomly select a farewell message from the list\n",
    "random_greetings = random.choice(greetings) # -------- Randomly select greeting message from the list\n",
    "\n",
    "# Test your chatbot\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in exits:\n",
    "        print(f\"\\nChatbot: {random_farewell}!\")\n",
    "        break\n",
    "    if user_input.lower() in ['hi', 'hello', 'hey', 'hi there']:\n",
    "        print(f\"\\nChatbot: {random_greetings}!\")\n",
    "    else:   \n",
    "        response = get_response(user_input)\n",
    "        print(f\"\\nChatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Model Technique</b></h3> <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "xtrain = tfidf_vectorizer.fit_transform(df['tokenized Questions'])\n",
    "# Xtrain is the preprocessed questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Transform the Y \n",
    "df['Answers_ID'] = le.fit_transform(df['Answers'])\n",
    "df.head()\n",
    "\n",
    "ytrain = df['Answers_ID'].values\n",
    "# ytrain is the transformed Answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>tokenized Questions</th>\n",
       "      <th>Answers_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).</td>\n",
       "      <td>who did the first work generally recognized a ai</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "      <td>what source wa drawn on the formation of the f...</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).</td>\n",
       "      <td>who created the hebbian learning rule</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.</td>\n",
       "      <td>when the first neural network is built</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.</td>\n",
       "      <td>what is the first neural network called</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Who did the first work generally recognized as...   \n",
       "1  What sources was drawn on the formation of the...   \n",
       "2             Who created the Hebbian learning rule?   \n",
       "3            When the first neural network is built?   \n",
       "4           What is the first neural network called?   \n",
       "\n",
       "                                             Answers  \\\n",
       "0          Warren McCulloch and Walter Pitts (1943).   \n",
       "1  knowledge of the basic physiology and function...   \n",
       "2                                Donald Hebb (1949).   \n",
       "3                                              1950.   \n",
       "4                                         The SNARC.   \n",
       "\n",
       "                                 tokenized Questions  Answers_ID  \n",
       "0   who did the first work generally recognized a ai         460  \n",
       "1  what source wa drawn on the formation of the f...         489  \n",
       "2              who created the hebbian learning rule         267  \n",
       "3             when the first neural network is built         171  \n",
       "4            what is the first neural network called         392  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       1.00      0.33      0.50         9\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       1.00      0.01      0.02       480\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         0\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.00      0.00      0.00         0\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         0\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         0\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         0\n",
      "         240       0.00      0.00      0.00         0\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.00      0.00      0.00         0\n",
      "         244       0.00      0.00      0.00         0\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         0\n",
      "         247       0.00      0.00      0.00         0\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.00      0.00      0.00         0\n",
      "         250       0.00      0.00      0.00         0\n",
      "         251       0.00      0.00      0.00         0\n",
      "         252       0.00      0.00      0.00         0\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.00      0.00      0.00         0\n",
      "         255       0.00      0.00      0.00         0\n",
      "         256       0.00      0.00      0.00         0\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         0\n",
      "         260       0.00      0.00      0.00         0\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       0.00      0.00      0.00         0\n",
      "         265       0.00      0.00      0.00         0\n",
      "         266       0.00      0.00      0.00         0\n",
      "         267       0.00      0.00      0.00         0\n",
      "         268       0.00      0.00      0.00         0\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.00      0.00      0.00         0\n",
      "         273       0.00      0.00      0.00         0\n",
      "         274       0.00      0.00      0.00         0\n",
      "         275       0.00      0.00      0.00         0\n",
      "         276       0.00      0.00      0.00         0\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.00      0.00      0.00         0\n",
      "         280       0.00      0.00      0.00         0\n",
      "         281       0.00      0.00      0.00         0\n",
      "         282       0.00      0.00      0.00         0\n",
      "         283       0.00      0.00      0.00         0\n",
      "         284       0.00      0.00      0.00         0\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       0.00      0.00      0.00         0\n",
      "         287       0.00      0.00      0.00         0\n",
      "         288       0.00      0.00      0.00         0\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.00      0.00      0.00         0\n",
      "         293       0.00      0.00      0.00         0\n",
      "         294       0.00      0.00      0.00         0\n",
      "         295       0.00      0.00      0.00         0\n",
      "         296       0.00      0.00      0.00         0\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         0\n",
      "         300       0.00      0.00      0.00         0\n",
      "         301       0.00      0.00      0.00         0\n",
      "         302       0.00      0.00      0.00         0\n",
      "         303       0.00      0.00      0.00         0\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.00      0.00      0.00         0\n",
      "         306       0.00      0.00      0.00         0\n",
      "         307       0.00      0.00      0.00         0\n",
      "         308       0.00      0.00      0.00         0\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.00      0.00      0.00         0\n",
      "         312       0.00      0.00      0.00         0\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         0\n",
      "         315       0.00      0.00      0.00         0\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         0\n",
      "         318       0.00      0.00      0.00         0\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         0\n",
      "         321       0.00      0.00      0.00         0\n",
      "         322       0.00      0.00      0.00         0\n",
      "         323       0.00      0.00      0.00         0\n",
      "         324       0.00      0.00      0.00         0\n",
      "         325       0.00      0.00      0.00         0\n",
      "         326       0.00      0.00      0.00         0\n",
      "         327       0.00      0.00      0.00         0\n",
      "         328       0.00      0.00      0.00         0\n",
      "         329       0.00      0.00      0.00         0\n",
      "         330       0.00      0.00      0.00         0\n",
      "         331       0.00      0.00      0.00         0\n",
      "         332       0.00      0.00      0.00         0\n",
      "         333       0.00      0.00      0.00         0\n",
      "         334       0.00      0.00      0.00         0\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       0.00      0.00      0.00         0\n",
      "         337       0.00      0.00      0.00         0\n",
      "         338       0.00      0.00      0.00         0\n",
      "         339       0.00      0.00      0.00         0\n",
      "         340       0.00      0.00      0.00         0\n",
      "         341       0.00      0.00      0.00         0\n",
      "         342       0.00      0.00      0.00         0\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.00      0.00      0.00         0\n",
      "         345       0.00      0.00      0.00         0\n",
      "         346       0.00      0.00      0.00         0\n",
      "         347       0.00      0.00      0.00         0\n",
      "         348       0.00      0.00      0.00         0\n",
      "         349       0.00      0.00      0.00         0\n",
      "         350       0.00      0.00      0.00         0\n",
      "         351       0.00      0.00      0.00         0\n",
      "         352       0.00      0.00      0.00         0\n",
      "         353       0.00      0.00      0.00         0\n",
      "         354       0.00      0.00      0.00         0\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         0\n",
      "         357       0.00      0.00      0.00         0\n",
      "         358       0.00      0.00      0.00         0\n",
      "         359       0.00      0.00      0.00         0\n",
      "         360       0.00      0.00      0.00         0\n",
      "         361       0.00      0.00      0.00         0\n",
      "         362       0.00      0.00      0.00         0\n",
      "         363       0.00      0.00      0.00         0\n",
      "         364       0.00      0.00      0.00         0\n",
      "         365       0.00      0.00      0.00         0\n",
      "         366       0.00      0.00      0.00         0\n",
      "         367       0.00      0.00      0.00         0\n",
      "         368       0.00      0.00      0.00         0\n",
      "         369       0.00      0.00      0.00         0\n",
      "         370       0.00      0.00      0.00         0\n",
      "         371       0.00      0.00      0.00         0\n",
      "         372       0.00      0.00      0.00         0\n",
      "         373       0.00      0.00      0.00         0\n",
      "         374       0.00      0.00      0.00         0\n",
      "         375       0.00      0.00      0.00         0\n",
      "         376       0.00      0.00      0.00         0\n",
      "         377       0.00      0.00      0.00         0\n",
      "         378       0.00      0.00      0.00         0\n",
      "         379       0.00      0.00      0.00         0\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.00      0.00      0.00         0\n",
      "         382       0.00      0.00      0.00         0\n",
      "         383       0.00      0.00      0.00         0\n",
      "         384       0.00      0.00      0.00         0\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         0\n",
      "         387       0.00      0.00      0.00         0\n",
      "         388       0.00      0.00      0.00         0\n",
      "         389       0.00      0.00      0.00         0\n",
      "         390       0.00      0.00      0.00         0\n",
      "         391       0.00      0.00      0.00         0\n",
      "         392       0.00      0.00      0.00         0\n",
      "         393       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         0\n",
      "         395       0.00      0.00      0.00         0\n",
      "         396       0.00      0.00      0.00         0\n",
      "         397       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         0\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         0\n",
      "         401       0.00      0.00      0.00         0\n",
      "         402       0.00      0.00      0.00         0\n",
      "         403       0.00      0.00      0.00         0\n",
      "         404       0.00      0.00      0.00         0\n",
      "         405       0.00      0.00      0.00         0\n",
      "         406       0.00      0.00      0.00         0\n",
      "         407       0.00      0.00      0.00         0\n",
      "         408       0.00      0.00      0.00         0\n",
      "         409       0.00      0.00      0.00         0\n",
      "         410       0.00      0.00      0.00         0\n",
      "         411       0.00      0.00      0.00         0\n",
      "         412       0.00      0.00      0.00         0\n",
      "         413       0.00      0.00      0.00         0\n",
      "         414       0.00      0.00      0.00         0\n",
      "         415       0.00      0.00      0.00         0\n",
      "         416       0.00      0.00      0.00         0\n",
      "         417       0.00      0.00      0.00         0\n",
      "         418       0.00      0.00      0.00         0\n",
      "         419       0.00      0.00      0.00         0\n",
      "         420       0.00      0.00      0.00         0\n",
      "         421       0.00      0.00      0.00         0\n",
      "         422       0.00      0.00      0.00         0\n",
      "         423       0.00      0.00      0.00         0\n",
      "         424       0.00      0.00      0.00         0\n",
      "         425       0.00      0.00      0.00         0\n",
      "         426       0.00      0.00      0.00         0\n",
      "         427       0.00      0.00      0.00         0\n",
      "         428       0.00      0.00      0.00         0\n",
      "         429       0.00      0.00      0.00         0\n",
      "         430       0.00      0.00      0.00         0\n",
      "         431       0.00      0.00      0.00         0\n",
      "         432       0.00      0.00      0.00         0\n",
      "         433       0.00      0.00      0.00         0\n",
      "         434       0.00      0.00      0.00         0\n",
      "         435       0.00      0.00      0.00         0\n",
      "         436       0.00      0.00      0.00         0\n",
      "         437       0.00      0.00      0.00         0\n",
      "         438       0.00      0.00      0.00         0\n",
      "         439       0.00      0.00      0.00         0\n",
      "         440       0.00      0.00      0.00         0\n",
      "         441       0.00      0.00      0.00         0\n",
      "         442       0.00      0.00      0.00         0\n",
      "         443       0.00      0.00      0.00         0\n",
      "         444       0.00      0.00      0.00         0\n",
      "         445       0.00      0.00      0.00         0\n",
      "         446       1.00      0.67      0.80         3\n",
      "         447       0.00      0.00      0.00         0\n",
      "         448       0.00      0.00      0.00         0\n",
      "         449       0.00      0.00      0.00         0\n",
      "         450       0.00      0.00      0.00         0\n",
      "         451       0.00      0.00      0.00         0\n",
      "         452       0.00      0.00      0.00         0\n",
      "         453       0.00      0.00      0.00         0\n",
      "         454       0.00      0.00      0.00         0\n",
      "         455       0.00      0.00      0.00         0\n",
      "         456       0.00      0.00      0.00         0\n",
      "         457       0.00      0.00      0.00         0\n",
      "         458       0.00      0.00      0.00         0\n",
      "         459       0.00      0.00      0.00         0\n",
      "         460       0.00      0.00      0.00         0\n",
      "         461       0.00      0.00      0.00         0\n",
      "         462       0.00      0.00      0.00         0\n",
      "         463       0.00      0.00      0.00         0\n",
      "         464       0.00      0.00      0.00         0\n",
      "         465       0.00      0.00      0.00         0\n",
      "         466       0.00      0.00      0.00         0\n",
      "         467       0.00      0.00      0.00         0\n",
      "         468       0.00      0.00      0.00         0\n",
      "         469       0.00      0.00      0.00         0\n",
      "         470       1.00      0.60      0.75         5\n",
      "         471       0.00      0.00      0.00         0\n",
      "         472       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.00      0.00      0.00         0\n",
      "         475       0.00      0.00      0.00         0\n",
      "         476       0.00      0.00      0.00         0\n",
      "         477       0.00      0.00      0.00         0\n",
      "         478       0.00      0.00      0.00         0\n",
      "         479       0.00      0.00      0.00         0\n",
      "         480       0.00      0.00      0.00         0\n",
      "         481       0.00      0.00      0.00         0\n",
      "         482       0.00      0.00      0.00         0\n",
      "         483       0.00      0.00      0.00         0\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       0.00      0.00      0.00         0\n",
      "         486       0.00      0.00      0.00         0\n",
      "         487       0.00      0.00      0.00         0\n",
      "         488       0.00      0.00      0.00         0\n",
      "         489       0.00      0.00      0.00         0\n",
      "         490       1.00      0.33      0.50         6\n",
      "         491       0.00      0.00      0.00         0\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03       503\n",
      "   macro avg       0.01      0.00      0.01       503\n",
      "weighted avg       1.00      0.03      0.04       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain, ytrain)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(xtrain, ytrain)\n",
    "\n",
    "train_predict = mnb.predict(xtrain)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(train_predict, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Yes' '\"Yes' '\"Yes' '\"Yes']\n",
      "\n",
      "Chatbot: None\n",
      "['\"Yes' '\"Yes' '\"Yes' '\"Yes']\n",
      "\n",
      "Chatbot: None\n",
      "\n",
      "Chatbot: Hi Human.... How can I help!\n",
      "['\"Yes' '\"Yes' '\"Yes' '\"Yes']\n",
      "\n",
      "Chatbot: None\n",
      "['\"Yes' '\"Yes' '\"Yes' '\"Yes']\n",
      "\n",
      "Chatbot: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\GMC\\PROJECT\\ai-chatbot\\yellowChat.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/GMC/PROJECT/ai-chatbot/yellowChat.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Test your chatbot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/GMC/PROJECT/ai-chatbot/yellowChat.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/GMC/PROJECT/ai-chatbot/yellowChat.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     user_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mYou: \u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/GMC/PROJECT/ai-chatbot/yellowChat.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m user_input\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m exits:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/GMC/PROJECT/ai-chatbot/yellowChat.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mChatbot: \u001b[39m\u001b[39m{\u001b[39;00mrandom_farewell\u001b[39m}\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1176\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1179\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1180\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def get_response(user_input):\n",
    "    global results\n",
    "    user_input_processed = preprocess_text(user_input) # ....................... Preprocess the user's input using the preprocess_text function\n",
    "\n",
    "    user_input_vector = tfidf_vectorizer.transform([user_input_processed])# .... Vectorize the preprocessed user input using the TF-IDF vectorizer\n",
    "\n",
    "    results = mnb.predict(user_input_vector)\n",
    "\n",
    "    for elem in results:\n",
    "        row_df = df.loc[df.isin([elem]).any(axis=1)]\n",
    "        print(row_df['Answers'].values)\n",
    "\n",
    "# create greeting list \n",
    "greetings = [\"Hey There.... I am a creation of Ehiz Danny Agba Coder.... How can I help\",\n",
    "            \"Hi Human.... How can I help\",\n",
    "            'Twale baba nla, wetin dey happen nah',\n",
    "            'How far Alaye, wetin happen'\n",
    "            \"Good Day .... How can I help\", \n",
    "            \"Hello There... How can I be useful to you today\",\n",
    "            \"Hi GomyCode Student.... How can I be of use\"]\n",
    "\n",
    "exits = ['thanks bye', 'bye', 'quit', 'exit', 'bye bye', 'close']\n",
    "farewell = ['Thanks....see you soon', 'Babye, See you soon', 'Bye... See you later', 'Bye... come back soon']\n",
    "\n",
    "random_farewell = random.choice(farewell) # ---------------- Randomly select a farewell message from the list\n",
    "random_greetings = random.choice(greetings) # -------- Randomly select greeting message from the list\n",
    "\n",
    "# Test your chatbot\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in exits:\n",
    "        print(f\"\\nChatbot: {random_farewell}!\")\n",
    "        break\n",
    "    if user_input.lower() in ['hi', 'hello', 'hey', 'hi there']:\n",
    "        print(f\"\\nChatbot: {random_greetings}!\")\n",
    "    else:   \n",
    "        response = get_response(user_input)\n",
    "        print(f\"\\nChatbot: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mya-ugeh",
   "language": "python",
   "name": "mya-ugeh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
